{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feffc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51709f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98de20ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'General Kenobi! 👋\\n\\nWhat can I do for you today?\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello there\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb181574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bfde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_post\",\n",
    "    \"Search and return information about Lilian Weng blog post on LLM agents, prompt engineering, and adversila attacts on LLms.\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960e8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b9505a",
   "metadata": {},
   "source": [
    "####  Retriver grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0928aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description = \"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "#llm with funcion call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e55b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \n",
    "If the document has words or meanings related to the question, mark it as relevant.  \n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e1eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrival_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3370716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='The generative agent architecture. (Image source: Park et al. 2023)'),\n",
       " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Table of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24bb754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88dd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(retrival_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f64308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Cristiano Ronaldo ?\"\n",
    "print(retrival_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d5304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed959106",
   "metadata": {},
   "source": [
    "### Data Generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2845c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20f9f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1adfb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='The generative agent architecture. (Image source: Park et al. 2023)'),\n",
       " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Table of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4662a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41a5d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is an AI Agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68addb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbcfdc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An AI agent is a computer program that can perform tasks autonomously.  \\n\\nIt uses a large language model (LLM) as its \"brain\" and is enhanced by components like memory, planning, and tool use to accomplish goals. \\nAutoGPT, GPT-Engineer, and BabyAGI are examples of AI agents.  \\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5423a2",
   "metadata": {},
   "source": [
    "### Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83c6698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b1180f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c8bb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.  \n",
    "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16d8803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucinations_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4d6cba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(hallucinations_grader.invoke({\"documents\": docs, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637b677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05008c3e",
   "metadata": {},
   "source": [
    "### Answer Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d96bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Answer Grader\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104fc7e",
   "metadata": {},
   "source": [
    "### Question Re-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8cb1201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.  \n",
    "You are given both a question and a document.  \n",
    "- First, check if the question is relevant to the document by identifying a connection or relevance between them.  \n",
    "- If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.  \n",
    "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase \n",
    "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
    "     \n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
    "             Here is the document: \\n\\n {documents} \\n ,\n",
    "             Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"who is a current indian Presudent of Kenya?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question not relevant \\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a757f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    filter_documents: List[str]\n",
    "    unfilter_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:AgentState):\n",
    "    print(\"----RETRIEVE----\")\n",
    "    question = state['question']\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb0517f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state:AgentState):\n",
    "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    unfiltered_docs = []\n",
    "    for doc in documents:\n",
    "        score = retrival_grader.invoke({\"question\":question, \"document\":doc})\n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
    "            unfiltered_docs.append(doc)\n",
    "    if len(unfiltered_docs) > 1:\n",
    "        return {\"unfilter_documents\": unfiltered_docs,\"filter_documents\":[], \"question\": question}\n",
    "    else:\n",
    "        return {\"filter_documents\": filtered_docs,\"unfilter_documents\":[],\"question\": question}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b29d611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state:AgentState):\n",
    "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
    "    state[\"question\"]\n",
    "    unfiltered_documents = state[\"unfilter_documents\"]\n",
    "    filtered_documents = state[\"filter_documents\"]\n",
    "    \n",
    "    \n",
    "    if unfiltered_documents:\n",
    "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
    "        return \"transform_query\"\n",
    "    if filtered_documents:\n",
    "        print(\"----DECISION: GENERATE----\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f78fc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"----GENERATE----\")\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e190d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "def transform_query(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    print(f\"this is my document{documents}\")\n",
    "    response = question_rewriter.invoke({\"question\":question,\"documents\":documents})\n",
    "    print(f\"----RESPONSE---- {response}\")\n",
    "    if response == 'question not relevant':\n",
    "        print(\"----QUESTION IS NOT AT ALL RELEVANT----\")\n",
    "        return {\"documents\":documents,\"question\":response,\"generation\":\"question was not at all relevant\"}\n",
    "    else:   \n",
    "        return {\"documents\":documents,\"question\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c59945ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_after_transformation(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    \n",
    "    if question==\"question not relevant\":\n",
    "        return \"query_not_at_all_relevant\"\n",
    "    else:\n",
    "        return \"Retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "719dd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"---CHECK HELLUCINATIONS---\")\n",
    "    question= state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    score = hallucinations_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
    "    \n",
    "    grade = score.binary_score\n",
    "    \n",
    "    #Check hallucinations\n",
    "    if grade=='yes':\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
    "        \n",
    "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "        \"not useful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c01852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e1e69ec",
   "metadata": {},
   "source": [
    "### From here Workflow will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a640565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x77a8948427b0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents) \n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x77a8948427b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
    "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")\n",
    "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
    "                            decide_to_generate,\n",
    "                            {\n",
    "                            \"generate\": \"Content_Generator\",\n",
    "                            \"transform_query\": \"Transform_User_Query\"\n",
    "                            }\n",
    "                            )\n",
    "workflow.add_conditional_edges(\"Content_Generator\",\n",
    "                            grade_generation_vs_documents_and_question,\n",
    "                            {\n",
    "                            \"useful\": END,\n",
    "                            \"not useful\": \"Transform_User_Query\",\n",
    "                            }\n",
    "                            )\n",
    "\n",
    "workflow.add_conditional_edges(\"Transform_User_Query\",\n",
    "                decide_to_generate_after_transformation,\n",
    "                {\n",
    "                \"Retriever\":\"Docs_Vector_Retrieve\",\n",
    "                \"query_not_at_all_relevant\":END\n",
    "                }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ed72eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1a759ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "430630bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01ef7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM-powered autonomous agents use short-term memory for in-context learning and long-term memory to store and recall information over extended periods. \\n\\nLong-term memory often utilizes an external vector store for fast retrieval of information. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 2141, 'total_tokens': 2193, 'completion_time': 0.094545455, 'prompt_time': 0.071098379, 'queue_time': 0.242509476, 'total_time': 0.165643834}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a49821e-f616-49a5-9bba-042e4548dfd3-0', usage_metadata={'input_tokens': 2141, 'output_tokens': 52, 'total_tokens': 2193})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bca38a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a prompt engineering?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e29091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Prompt engineering is the practice of designing effective prompts to guide the behavior of large language models (LLMs).  It involves finding ways to communicate with LLMs to elicit desired responses without altering the model's underlying weights.  This is an empirical field requiring experimentation and refinement to achieve optimal results. \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1108, 'total_tokens': 1171, 'completion_time': 0.114545455, 'prompt_time': 0.037272728, 'queue_time': 0.265938755, 'total_time': 0.151818183}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--57820a31-075e-4931-a74f-72a6a1f80deb-0', usage_metadata={'input_tokens': 1108, 'output_tokens': 63, 'total_tokens': 1171})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf1cfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of data structure while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9efaf94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The generative agent architecture. (Image source: Park et al. 2023)'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Table of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).')]\n",
      "----RESPONSE---- How does the use of a vector store and fast retrieval contribute to the long-term memory of an LLM-powered autonomous agent? \n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the use of a vector store and fast retrieval contribute to the long-term memory of an LLM-powered autonomous agent? \\n\\n\\n',\n",
       " 'generation': AIMessage(content='An external vector store allows the agent to store a vast amount of information, and fast retrieval enables the agent to quickly access this information when needed. This combination provides the long-term memory necessary for the agent to learn from past experiences and make informed decisions. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 2078, 'total_tokens': 2133, 'completion_time': 0.1, 'prompt_time': 0.068505916, 'queue_time': 0.24270598799999998, 'total_time': 0.168505916}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b3bb4dd3-c262-4051-abc3-5a0994332155-0', usage_metadata={'input_tokens': 2078, 'output_tokens': 55, 'total_tokens': 2133}),\n",
       " 'documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       "  Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:')],\n",
       " 'filter_documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       "  Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:')],\n",
       " 'unfilter_documents': []}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f0f80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of c language and php while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fda56988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.')]\n",
      "----RESPONSE---- How do LLMs and other programming languages like PHP contribute to the development of AI agent architectures described in this document? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable. Did you mean: 'pprint.pprint(...)'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JIM/Langgraph/env/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2852\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2849\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2850\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2852\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2857\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2859\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2860\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2861\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2864\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2865\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JIM/Langgraph/env/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2542\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2541\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2548\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2549\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2551\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2552\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JIM/Langgraph/env/lib/python3.13/site-packages/langgraph/graph/branch.py:169\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    168\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JIM/Langgraph/env/lib/python3.13/site-packages/langgraph/utils/runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mgrade_generation_vs_documents_and_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnot useful\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnot useful\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable. Did you mean: 'pprint.pprint(...)'?",
      "During task with name 'Content_Generator' and id 'f30a551b-62ce-2cd6-fddb-3005dd165713'"
     ]
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbb5dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='},\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",'), Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.'}, page_content='Tips for Example Selection#'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'language': 'en', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'language': 'en', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'title': \"Prompt Engineering | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content='For closed-book QA, each demonstration is formatted as follows to construct few-shot prompts. Swapping the question with the evidence (longer distance between questions and answers) is found to consistently yield lower results across all datasets.\\nEvidence: ...\\nQuestion: ...\\nAnswer: ...\\nThe answer probability is computed in three ways:')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'language': 'en', 'title': \"Prompt Engineering | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.'}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'title': \"Prompt Engineering | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'title': \"Prompt Engineering | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='For closed-book QA, each demonstration is formatted as follows to construct few-shot prompts. Swapping the question with the evidence (longer distance between questions and answers) is found to consistently yield lower results across all datasets.\\nEvidence: ...\\nQuestion: ...\\nAnswer: ...\\nThe answer probability is computed in three ways:')]\n",
      "----RESPONSE---- What strategies have been found to be effective in prompting language models for question answering tasks, particularly in closed-book scenarios? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Several effective strategies for prompting language models in closed-book scenarios include providing explicit context within the prompt, using chain-of-thought prompting to guide reasoning, and incorporating retrieved knowledge from external sources.  Experimentation and careful selection of prompt engineering methods are crucial for optimal performance as their effectiveness can vary across different models.  \\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1138, 'total_tokens': 1206, 'completion_time': 0.123636364, 'prompt_time': 0.038477413, 'queue_time': 0.24106621899999997, 'total_time': 0.162113777}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a1126727-6a9a-48e6-b490-465e26b00672-0', usage_metadata={'input_tokens': 1138, 'output_tokens': 68, 'total_tokens': 1206})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"who is a first president of USA?\"}\n",
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24a995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
